# import 

# listen for now just limit by the final fricking representation files... 29,31,54.  
# later you can actually rerun ornet and figure out where ornet-outputs came from and why there's 80 instances in single_cells/llo

# before working on this doc:
# save models (in workspace ig) -> drivers
# hook representations, save in wkspace ig. 

# load cnn feature dicts, cnn+roi feature dicts
# load cnn+lstm feature dicts (exactly where should we hook them?)
# load intermediate feature dicts

# Figure out how comparable they are
# figure out what we doing with intermediates -> same as Neelima?? 

# Run a few classification models on all. like svm, random forest, etc
# delany should do this. 