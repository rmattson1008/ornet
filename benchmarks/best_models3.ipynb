{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "from models import BaseCNN, VGG_Model, ResNet18, ResBlock\n",
    "from parsing_utils import make_parser\n",
    "\n",
    "from cnn_driver import test, get_dataloaders, get_deep_features\n",
    "from benchmarks import run_benchmarks\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[hparams table - google sheets link](https://docs.google.com/spreadsheets/d/1XOCA3YayXT9NfAM0j9SgO9KCypA4LZj766u6BDgU_UE/edit?usp=sharing)\n",
    "\n",
    "[tensorboard training data - adam](https://tensorboard.dev/experiment/BMkn3PX8RAe6QrzwpWLd4g/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/cuda/__init__.py:82: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/c10/cuda/CUDAFunctions.cpp:112.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "args, _ = make_parser()\n",
    "args.input_dir = \"/data/ornet/single_cells_cnns\"\n",
    "device = 'cpu' if args.cuda == 0 or not torch.cuda.is_available() else 'cuda'\n",
    "device = torch.device(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(73)\n",
    "else:\n",
    "    torch.manual_seed(73)\n",
    "\n",
    "path_to_intermediates = \"/data/ornet/gmm_intermediates\"\n",
    "accept_list = []\n",
    "for subdir in args.classes:\n",
    "    path = os.path.join(path_to_intermediates, subdir)\n",
    "    files = os.listdir(path)\n",
    "    accept_list.extend([x.split(\".\")[0]\n",
    "                        for x in files if 'normalized' in x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Global model\n",
    "Hparams:    \n",
    "- Lr = 0.00001\n",
    "- batch_size = 32\n",
    "- Shuffle =\t0\t\n",
    "- wd = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using global image inputs\n",
      "/data/ornet/single_cells_cnns\n",
      "Testing\n",
      "Accuracy: tensor(0.6667, device='cuda:0')\n",
      "['control', 'mdivi', 'llo']\n",
      "[[0 0 3]\n",
      " [0 3 1]\n",
      " [0 0 5]]\n",
      "Getting deep features\n",
      "best performance at epoch 43\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarks for MDIVI vs LLO\n",
      "RandomForestClassifier()  accuracy: 0.8888888888888888\n",
      "[[3 0]\n",
      " [1 5]]\n",
      "KNeighborsClassifier() accuracy: 1.0\n",
      "[[4 0]\n",
      " [0 5]]\n",
      "DecisionTreeClassifier() accuracy: 1.0\n",
      "[[4 0]\n",
      " [0 5]]\n",
      "Benchmarks for Control vs LLO\n",
      "RandomForestClassifier()  accuracy: 0.75\n",
      "[[2 1]\n",
      " [1 4]]\n",
      "KNeighborsClassifier() accuracy: 0.75\n",
      "[[2 1]\n",
      " [1 4]]\n",
      "DecisionTreeClassifier() accuracy: 0.625\n",
      "[[1 1]\n",
      " [2 4]]\n",
      "Benchmarks for MDIVI vs Control\n",
      "RandomForestClassifier()  accuracy: 1.0\n",
      "[[3 0]\n",
      " [0 4]]\n",
      "KNeighborsClassifier() accuracy: 1.0\n",
      "[[3 0]\n",
      " [0 4]]\n",
      "DecisionTreeClassifier() accuracy: 0.8571428571428571\n",
      "[[3 1]\n",
      " [0 3]]\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18(in_channels=2, resblock=ResBlock, outputs=3)\n",
    "model.to(device)\n",
    "args.roi = False\n",
    "train_dataloader, test_dataloader, val_dataloader = get_dataloaders(\n",
    "    args, accept_list, resize=224)\n",
    "\n",
    "args.save_model = \"/home/rachel/ornet/models/glob_res_adam11_1e-05_32_False_500_0.01.pth\"\n",
    "# args.save_model = \"/home/rachel/ornet/models/glob_res_adam11_1e-05_64_False_500_0.01.pth\"\n",
    "checkpoint = torch.load(args.save_model)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Testing\")\n",
    "test(args, model, test_dataloader, device=device)\n",
    "\n",
    "loader_dict = {\n",
    "            \"train\": train_dataloader, \"test\": test_dataloader, \"val\": val_dataloader\n",
    "        }\n",
    "feats = get_deep_features(args, model, loader_dict, device=device)\n",
    "run_benchmarks(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Local model\n",
    "Hparams:   \n",
    "bs - 16\n",
    "lr = 0.001\n",
    "wd = 0.1\n",
    "Shuffle = True\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "<!-- \n",
    "lr = 0.00006\n",
    "bs = 16\n",
    "shuffle = 1\n",
    "wd = 0.01\n",
    "\n",
    "\n",
    "- Lr = 0.001\n",
    "- batch_size = 64 -->\n",
    "<!-- - Shuffle =\t1 -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ROI inputs\n",
      "/data/ornet/single_cells_cnns\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/rachel/ornet/benchmarks/best_models3.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000007vscode-remote?line=5'>6</a>\u001b[0m \u001b[39m# args.save_model = \"/home/rachel/ornet/models/roi_res_adam10_0.001_16_True_300_0.1.pth\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000007vscode-remote?line=6'>7</a>\u001b[0m \u001b[39m# args.save_model = \"/home/rachel/ornet/models/glob_res_adam10_1e-05_16_True_500_0.1.pth\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000007vscode-remote?line=7'>8</a>\u001b[0m args\u001b[39m.\u001b[39msave_model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/rachel/ornet/models/glob_res_adam10_1e-06_16_False_500_0.1.pth\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000007vscode-remote?line=8'>9</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(args\u001b[39m.\u001b[39;49msave_model)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000007vscode-remote?line=9'>10</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000007vscode-remote?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTesting\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py:712\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=709'>710</a>\u001b[0m             opened_file\u001b[39m.\u001b[39mseek(orig_position)\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=710'>711</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(opened_file)\n\u001b[0;32m--> <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=711'>712</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=712'>713</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m~/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py:1046\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=1043'>1044</a>\u001b[0m unpickler \u001b[39m=\u001b[39m UnpicklerWrapper(data_file, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[1;32m   <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=1044'>1045</a>\u001b[0m unpickler\u001b[39m.\u001b[39mpersistent_load \u001b[39m=\u001b[39m persistent_load\n\u001b[0;32m-> <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=1045'>1046</a>\u001b[0m result \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m   <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=1047'>1048</a>\u001b[0m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=1049'>1050</a>\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py:1016\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=1013'>1014</a>\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m loaded_storages:\n\u001b[1;32m   <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=1014'>1015</a>\u001b[0m     nbytes \u001b[39m=\u001b[39m numel \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=1015'>1016</a>\u001b[0m     load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))\n\u001b[1;32m   <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=1017'>1018</a>\u001b[0m \u001b[39mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m~/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py:1001\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=996'>997</a>\u001b[0m storage \u001b[39m=\u001b[39m zip_file\u001b[39m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[39m.\u001b[39m_UntypedStorage)\u001b[39m.\u001b[39mstorage()\u001b[39m.\u001b[39m_untyped()\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=997'>998</a>\u001b[0m \u001b[39m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=998'>999</a>\u001b[0m \u001b[39m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=999'>1000</a>\u001b[0m loaded_storages[key] \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstorage\u001b[39m.\u001b[39m_TypedStorage(\n\u001b[0;32m-> <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=1000'>1001</a>\u001b[0m     wrap_storage\u001b[39m=\u001b[39mrestore_location(storage, location),\n\u001b[1;32m   <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=1001'>1002</a>\u001b[0m     dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py:176\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=173'>174</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=174'>175</a>\u001b[0m     \u001b[39mfor\u001b[39;00m _, _, fn \u001b[39min\u001b[39;00m _package_registry:\n\u001b[0;32m--> <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=175'>176</a>\u001b[0m         result \u001b[39m=\u001b[39m fn(storage, location)\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=176'>177</a>\u001b[0m         \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=177'>178</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py:152\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=149'>150</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=150'>151</a>\u001b[0m     \u001b[39mif\u001b[39;00m location\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=151'>152</a>\u001b[0m         device \u001b[39m=\u001b[39m validate_cuda_device(location)\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=152'>153</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m_torch_load_uninitialized\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=153'>154</a>\u001b[0m             storage_type \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(torch\u001b[39m.\u001b[39mcuda, \u001b[39mtype\u001b[39m(obj)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py:136\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=132'>133</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39m_utils\u001b[39m.\u001b[39m_get_device_index(location, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=134'>135</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available():\n\u001b[0;32m--> <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=135'>136</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mAttempting to deserialize object on a CUDA \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=136'>137</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=137'>138</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mIf you are running on a CPU-only machine, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=138'>139</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39mcpu\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=139'>140</a>\u001b[0m                        \u001b[39m'\u001b[39m\u001b[39mto map your storages to the CPU.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=140'>141</a>\u001b[0m device_count \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mdevice_count()\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=141'>142</a>\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "\n",
    "model = ResNet18(in_channels=2, resblock=ResBlock, outputs=3)\n",
    "model.to(device)\n",
    "args.roi = True\n",
    "train_dataloader, test_dataloader, val_dataloader = get_dataloaders(\n",
    "    args, accept_list, resize=224)\n",
    "# args.save_model = \"/home/rachel/ornet/models/roi_res_adam10_0.001_16_True_300_0.1.pth\"\n",
    "# args.save_model = \"/home/rachel/ornet/models/glob_res_adam10_1e-05_16_True_500_0.1.pth\"\n",
    "args.save_model = \"/home/rachel/ornet/models/glob_res_adam10_1e-06_16_False_500_0.1.pth\"\n",
    "checkpoint = torch.load(args.save_model)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Testing\")\n",
    "test(args, model, test_dataloader, device=device)\n",
    "loader_dict = {\n",
    "            \"train\": train_dataloader, \"test\": test_dataloader, \"val\": val_dataloader\n",
    "        }\n",
    "feats = get_deep_features(args, model, loader_dict, device=device)\n",
    "run_benchmarks(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Best Global model\n",
    "- 0.001\n",
    "- 64\n",
    "- False\n",
    "\n",
    "and\n",
    "\n",
    "-0.00001\n",
    "- 64\n",
    "- Shufle\n",
    "- wd 0 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using global image inputs\n",
      "/data/ornet/single_cells_cnns\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/rachel/ornet/keep_models/glob_base_adam9_1e-05_64_True_500_0.1.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/rachel/ornet/benchmarks/best_models3.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000010vscode-remote?line=6'>7</a>\u001b[0m \u001b[39m# args.save_model = \"/home/rachel/ornet/models/glob_base_adam_0.001_64_False_300.pth\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000010vscode-remote?line=7'>8</a>\u001b[0m \u001b[39m# args.save_model = \"/home/rachel/ornet/keep_models/glob_base_adam7_1e-05_64_True_500.pth\"\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000010vscode-remote?line=8'>9</a>\u001b[0m \u001b[39m# args.save_model = \"/home/rachel/ornet/models/glob_base_adam8_1e-05_64_True_1000_0.0.pth\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000010vscode-remote?line=9'>10</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000010vscode-remote?line=10'>11</a>\u001b[0m \u001b[39m# args.save_model = \"/home/rachel/ornet/models/glob_base_adam9_0.0001_64_True_500_0.01.pth\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000010vscode-remote?line=11'>12</a>\u001b[0m \u001b[39m# args.save_model = \"/home/rachel/ornet/models/glob_base_adam9_0.0001_16_True_500_0.1.pth\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000010vscode-remote?line=12'>13</a>\u001b[0m args\u001b[39m.\u001b[39msave_model \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/rachel/ornet/keep_models/glob_base_adam9_1e-05_64_True_500_0.1.pth\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000010vscode-remote?line=13'>14</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(args\u001b[39m.\u001b[39;49msave_model)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000010vscode-remote?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(checkpoint[\u001b[39m'\u001b[39m\u001b[39mstate_dict\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B7b22686f73744e616d65223a226c6f67616e2e63732e7567612e656475222c2275736572223a2272616368656c227d/home/rachel/ornet/benchmarks/best_models3.ipynb#ch0000010vscode-remote?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTesting\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=695'>696</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=696'>697</a>\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=698'>699</a>\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=699'>700</a>\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=700'>701</a>\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=701'>702</a>\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=702'>703</a>\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=703'>704</a>\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py:231\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=228'>229</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=229'>230</a>\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=230'>231</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=231'>232</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=232'>233</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py:212\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=210'>211</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> <a href='file:///home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/torch/serialization.py?line=211'>212</a>\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/rachel/ornet/keep_models/glob_base_adam9_1e-05_64_True_500_0.1.pth'"
     ]
    }
   ],
   "source": [
    "model = BaseCNN()\n",
    "model.to(device)\n",
    "args.roi = False\n",
    "train_dataloader, test_dataloader, val_dataloader = get_dataloaders(\n",
    "    args, accept_list, resize=28)\n",
    "\n",
    "# args.save_model = \"/home/rachel/ornet/models/glob_base_adam_0.001_64_False_300.pth\"\n",
    "# args.save_model = \"/home/rachel/ornet/keep_models/glob_base_adam7_1e-05_64_True_500.pth\"\n",
    "# args.save_model = \"/home/rachel/ornet/models/glob_base_adam8_1e-05_64_True_1000_0.0.pth\"\n",
    "\n",
    "# args.save_model = \"/home/rachel/ornet/models/glob_base_adam9_0.0001_64_True_500_0.01.pth\"\n",
    "# args.save_model = \"/home/rachel/ornet/models/glob_base_adam9_0.0001_16_True_500_0.1.pth\"\n",
    "args.save_model = \"/home/rachel/ornet/models/glob_base_adam9_1e-05_64_True_500_0.1.pth\"\n",
    "checkpoint = torch.load(args.save_model)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Testing\")\n",
    "test(args, model, test_dataloader, device=device)\n",
    "\n",
    "loader_dict = {\n",
    "            \"train\": train_dataloader, \"test\": test_dataloader, \"val\": val_dataloader\n",
    "        }\n",
    "feats = get_deep_features(args, model, loader_dict, device=device)\n",
    "run_benchmarks(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best on Local\n",
    "\n",
    "- 0.0001\n",
    "- 64\n",
    "- False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ROI inputs\n",
      "/data/ornet/single_cells_cnns\n",
      "Testing\n",
      "Accuracy: tensor(0.6667, device='cuda:0')\n",
      "['control', 'mdivi', 'llo']\n",
      "[[2 0 1]\n",
      " [1 1 2]\n",
      " [0 0 5]]\n",
      "Getting deep features\n",
      "best performance at epoch 144\n",
      "Benchmarks for MDIVI vs LLO\n",
      "RandomForestClassifier()  accuracy: 0.5555555555555556\n",
      "[[0 0]\n",
      " [4 5]]\n",
      "KNeighborsClassifier() accuracy: 0.6666666666666666\n",
      "[[1 0]\n",
      " [3 5]]\n",
      "DecisionTreeClassifier() accuracy: 0.5555555555555556\n",
      "[[0 0]\n",
      " [4 5]]\n",
      "Benchmarks for Control vs LLO\n",
      "RandomForestClassifier()  accuracy: 0.75\n",
      "[[1 0]\n",
      " [2 5]]\n",
      "KNeighborsClassifier() accuracy: 0.875\n",
      "[[2 0]\n",
      " [1 5]]\n",
      "DecisionTreeClassifier() accuracy: 0.75\n",
      "[[1 0]\n",
      " [2 5]]\n",
      "Benchmarks for MDIVI vs Control\n",
      "RandomForestClassifier()  accuracy: 0.7142857142857143\n",
      "[[3 2]\n",
      " [0 2]]\n",
      "KNeighborsClassifier() accuracy: 0.7142857142857143\n",
      "[[3 2]\n",
      " [0 2]]\n",
      "DecisionTreeClassifier() accuracy: 0.5714285714285714\n",
      "[[3 3]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "model = BaseCNN()\n",
    "model.to(device)\n",
    "args.roi = True\n",
    "train_dataloader, test_dataloader, val_dataloader = get_dataloaders(\n",
    "    args, accept_list, resize=28)\n",
    "\n",
    "# args.save_model = \"/home/rachel/ornet/models/roi_base_adam_0.0001_64_False_300.pth\"\n",
    "# args.save_model = \"/home/rachel/ornet/keep_models/roi_base_adam7_0.0001_64_True_500.pth\"\n",
    "args.save_model = \"/home/rachel/ornet/models/roi_base_adam8_ws_0.0001_64_False_500_0.01.pth\"\n",
    "\n",
    "checkpoint = torch.load(args.save_model)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "print(\"Testing\")\n",
    "test(args, model, test_dataloader, device=device)\n",
    "\n",
    "loader_dict = {\n",
    "            \"train\": train_dataloader, \"test\": test_dataloader, \"val\": val_dataloader\n",
    "        }\n",
    "feats = get_deep_features(args, model, loader_dict, device=device)\n",
    "run_benchmarks(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a690693c1fdd9d71c81918a527effb7319205501255b3eea75f291099e2d6564"
  },
  "kernelspec": {
   "display_name": "Python (ornet)",
   "language": "python",
   "name": "ornet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
