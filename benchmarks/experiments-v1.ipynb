{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments - May 18, 2022\n",
    "\n",
    "\n",
    "Hyperparam choices:\n",
    "\n",
    "Criterion = CrossEntropyLoss  \n",
    "Optimizer = SGD\n",
    "num_epochs = 300  \n",
    "Random split generator seeded: 73    \n",
    "batch_size = 10\n",
    "\n",
    "- TODO - stop when val stops improving  \n",
    "\n",
    "\n",
    "### [Global Image](#1.1)\n",
    "1. unweighted \n",
    "    - 1.1 [Base CNN - scaled down to 28x28](#1.1)\n",
    "    - 1.2 [ResNet - scaled down to 212x212](#1.2)\n",
    "\n",
    "2. weighted sample\n",
    "    - 2.1 [Base CNN - scaled  down to 28x28](#2.1)\n",
    "    - 2.2 [ResNet - scaled down to 212x212](#2.2)\n",
    "\n",
    "### [Local ROI](#3.1)\n",
    "3. unweighted\n",
    "    - 3.1 [Base CNN - cropped 28x28 roi](#3.1)\n",
    "    - 3.2 [ResNet - roi interpolated/scaled up to 212x212](#3.2)\n",
    "\n",
    "4. weighted sampling\n",
    "    - 4.1 [Base CNN - cropped 28x28 roi](#4.1)\n",
    "    - 4.2 [ResNet - roi interpolated/scaled up to 212x212](#4.2)\n",
    "\n",
    "\n",
    "Experiments TBD - cnn-lstm. factors are weighted sampling +/-, sequence length like 1-50, can swap in resnet or pretrain some.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rachel/anaconda3/envs/ornet/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from cnn_driver import train, test, get_dataloaders\n",
    "from parsing_utils import make_parser\n",
    "from models import BaseCNN, VGG_Model, ResNet18, ResBlock\n",
    "\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JupyterArgs:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 10\n",
    "        self.roi = False\n",
    "        self.weighted_samples = False\n",
    "        self.cuda = -1\n",
    "        self.lr = 1e-3\n",
    "        self.epochs = 300\n",
    "        self.classes= ['control', 'mdivi', 'llo']\n",
    "        self.input_dir = \"/data/ornet/single_cells_cnns\"\n",
    "        self.save = True\n",
    "        self.save_dir = \"/home/rachel/ornet/models/\"\n",
    "        self.save_as = \"model1.pth\"\n",
    "        self.train = False\n",
    "\n",
    "args = JupyterArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "we have more segmented cell videos saved on logan then intermediates.\n",
    "best to rerun ornet on raw data, but till discrepancy is resolved this\n",
    "will result in using the 114 samples that Neelima used in the last scipy submit\n",
    "class balance 29, 31, 54\n",
    "\"\"\"\n",
    "path_to_intermediates = \"/data/ornet/gmm_intermediates\"\n",
    "accept_list = []\n",
    "for subdir in args.classes:\n",
    "    path = os.path.join(path_to_intermediates, subdir)\n",
    "    for file in os.listdir(path):\n",
    "        if 'normalized' in file:\n",
    "            accept_list.append(file.split(\".\")[0])\n",
    "\n",
    "device = 'cpu' if not torch.cuda.is_available() else 'cuda'\n",
    "device = torch.device(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global image\n",
    "\n",
    "<a id='1.1'></a>\n",
    "1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using global image inputs\n",
      "/data/ornet/single_cells_cnns\n",
      "91\n",
      "91\n",
      "Training\n",
      "Testing\n",
      "Accuracy: tensor(0.2500, device='cuda:0')\n",
      "['control', 'mdivi', 'llo']\n",
      "[[0 2 0]\n",
      " [0 0 2]\n",
      " [4 1 3]]\n"
     ]
    }
   ],
   "source": [
    "# 1.1\n",
    "\n",
    "\n",
    "args.save_as = \"global_BaseCNN_unweighted_05-18.pth\"\n",
    "args.roi=False\n",
    "args.weighted_samples = False\n",
    "\n",
    "train_dataloader, test_dataloader, val_dataloader = get_dataloaders(\n",
    "    args, accept_list, resize=28)\n",
    "\n",
    "model = BaseCNN()\n",
    "# model = ResNet18(in_channels=2, resblock=ResBlock, outputs=3)\n",
    "model.to(device)\n",
    "\n",
    "if args.train:\n",
    "    print(\"Training\")\n",
    "    train(args, model, train_dataloader, val_dataloader, device=device)\n",
    "\n",
    "saved_state = torch.load(os.path.join(args.save_dir, args.save_as))\n",
    "model.load_state_dict(saved_state)\n",
    "print(\"Testing\")\n",
    "test(args, model, test_dataloader, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1.2'></a>\n",
    "1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using global image inputs\n",
      "/data/ornet/single_cells_cnns\n",
      "91\n",
      "91\n",
      "Testing\n",
      "Accuracy: tensor(0.5000, device='cuda:0')\n",
      "['control', 'mdivi', 'llo']\n",
      "[[0 1 1]\n",
      " [0 2 0]\n",
      " [4 0 4]]\n"
     ]
    }
   ],
   "source": [
    "# 1.2\n",
    "args.save_as = \"global_ResNet_unweighted_05-18.pth\"\n",
    "args.roi=False\n",
    "args.weighted_samples = False\n",
    "\n",
    "train_dataloader, test_dataloader, val_dataloader = get_dataloaders(\n",
    "    args, accept_list, resize=224)\n",
    "\n",
    "# model = BaseCNN()\n",
    "model = ResNet18(in_channels=2, resblock=ResBlock, outputs=3)\n",
    "model.to(device)\n",
    "\n",
    "if args.train:\n",
    "    print(\"Training\")\n",
    "    train(args, model, train_dataloader, val_dataloader, device=device)\n",
    "\n",
    "saved_state = torch.load(os.path.join(args.save_dir, args.save_as))\n",
    "model.load_state_dict(saved_state)\n",
    "print(\"Testing\")\n",
    "test(args, model, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.1'></a>\n",
    "2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using global image inputs\n",
      "/data/ornet/single_cells_cnns\n",
      "91\n",
      "91\n",
      "using weighted sampling\n",
      "Testing\n",
      "Accuracy: tensor(0.3333, device='cuda:0')\n",
      "['control', 'mdivi', 'llo']\n",
      "[[0 2 0]\n",
      " [1 1 0]\n",
      " [4 1 3]]\n"
     ]
    }
   ],
   "source": [
    "# 2.1\n",
    "args.save_as = \"global_BaseCNN_weighted_05-18.pth\"\n",
    "args.weighted_samples = True\n",
    "\n",
    "train_dataloader, test_dataloader, val_dataloader = get_dataloaders(\n",
    "    args, accept_list, resize=28)\n",
    "\n",
    "model = BaseCNN()\n",
    "# model = ResNet18(in_channels=2, resblock=ResBlock, outputs=3)\n",
    "model.to(device)\n",
    "\n",
    "if args.train:\n",
    "    print(\"Training\")\n",
    "    train(args, model, train_dataloader, val_dataloader, device=device)\n",
    "\n",
    "saved_state = torch.load(os.path.join(args.save_dir, args.save_as))\n",
    "model.load_state_dict(saved_state)\n",
    "print(\"Testing\")\n",
    "test(args, model, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2.2'></a>\n",
    "2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using global image inputs\n",
      "/data/ornet/single_cells_cnns\n",
      "91\n",
      "91\n",
      "using weighted sampling\n",
      "Testing\n",
      "Accuracy: tensor(0.3333, device='cuda:0')\n",
      "['control', 'mdivi', 'llo']\n",
      "[[1 1 0]\n",
      " [2 0 0]\n",
      " [5 0 3]]\n"
     ]
    }
   ],
   "source": [
    "# 2.2\n",
    "args.save_as = \"global_ResNet_weighted_05-18.pth\"\n",
    "args.weighted_samples = True\n",
    "\n",
    "train_dataloader, test_dataloader, val_dataloader = get_dataloaders(\n",
    "    args, accept_list, resize=224)\n",
    "\n",
    "# model = BaseCNN()\n",
    "model = ResNet18(in_channels=2, resblock=ResBlock, outputs=3)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "if args.train:\n",
    "    print(\"Training\")\n",
    "    train(args, model, train_dataloader, val_dataloader, device=device)\n",
    "\n",
    "saved_state = torch.load(os.path.join(args.save_dir, args.save_as))\n",
    "model.load_state_dict(saved_state)\n",
    "print(\"Testing\")\n",
    "test(args, model, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROI Image\n",
    "<a id='3.1'></a>\n",
    "3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ROI inputs\n",
      "/data/ornet/single_cells_cnns\n",
      "91\n",
      "91\n",
      "Testing\n",
      "Accuracy: tensor(0.5833, device='cuda:0')\n",
      "['control', 'mdivi', 'llo']\n",
      "[[1 1 0]\n",
      " [1 0 1]\n",
      " [1 1 6]]\n"
     ]
    }
   ],
   "source": [
    "# 3.1\n",
    "args.save_as = \"roi_BaseCNN_unweighted_05-18.pth\"\n",
    "saved_models.append(args.save_as)\n",
    "args.roi = True\n",
    "args.weighted_samples = False\n",
    "\n",
    "train_dataloader, test_dataloader, val_dataloader = get_dataloaders(\n",
    "    args, accept_list, resize=28)\n",
    "\n",
    "model = BaseCNN()\n",
    "# model = ResNet18(in_channels=2, resblock=ResBlock, outputs=3)\n",
    "model.to(device)\n",
    "\n",
    "if args.train:\n",
    "    print(\"Training\")\n",
    "    train(args, model, train_dataloader, val_dataloader, device=device)\n",
    "\n",
    "saved_state = torch.load(os.path.join(args.save_dir, args.save_as))\n",
    "model.load_state_dict(saved_state)\n",
    "print(\"Testing\")\n",
    "test(args, model, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3.2'></a>\n",
    "3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ROI inputs\n",
      "/data/ornet/single_cells_cnns\n",
      "91\n",
      "91\n",
      "Testing\n",
      "Accuracy: tensor(0.5833, device='cuda:0')\n",
      "['control', 'mdivi', 'llo']\n",
      "[[1 0 1]\n",
      " [1 0 1]\n",
      " [2 0 6]]\n"
     ]
    }
   ],
   "source": [
    "# 3.2\n",
    "args.save_as = \"roi_ResNet_unweighted_05-18.pth\"\n",
    "saved_models.append(args.save_as)\n",
    "args.roi = True\n",
    "args.weighted_samples = False\n",
    "\n",
    "train_dataloader, test_dataloader, val_dataloader = get_dataloaders(\n",
    "    args, accept_list, resize=224)\n",
    "\n",
    "# model = BaseCNN()\n",
    "model = ResNet18(in_channels=2, resblock=ResBlock, outputs=3)\n",
    "model.to(device)\n",
    "\n",
    "if args.train:\n",
    "    print(\"Training\")\n",
    "    train(args, model, train_dataloader, val_dataloader, device=device)\n",
    "\n",
    "saved_state = torch.load(os.path.join(args.save_dir, args.save_as))\n",
    "model.load_state_dict(saved_state)\n",
    "print(\"Testing\")\n",
    "test(args, model, test_dataloader, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.1'></a>\n",
    "4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ROI inputs\n",
      "/data/ornet/single_cells_cnns\n",
      "91\n",
      "91\n",
      "using weighted sampling\n",
      "Testing\n",
      "Accuracy: tensor(0.7500, device='cuda:0')\n",
      "['control', 'mdivi', 'llo']\n",
      "[[2 0 0]\n",
      " [0 2 0]\n",
      " [0 3 5]]\n"
     ]
    }
   ],
   "source": [
    "# 4.1\n",
    "args.save_as = \"roi_BaseCNN_weighted_05-18.pth\"\n",
    "saved_models.append(args.save_as)\n",
    "args.roi = True\n",
    "args.weighted_samples = True\n",
    "\n",
    "\n",
    "train_dataloader, test_dataloader, val_dataloader = get_dataloaders(\n",
    "    args, accept_list, resize=28)\n",
    "\n",
    "model = BaseCNN()\n",
    "# model = ResNet18(in_channels=2, resblock=ResBlock, outputs=3)\n",
    "model.to(device)\n",
    "\n",
    "if args.train:\n",
    "    print(\"Training\")\n",
    "    train(args, model, train_dataloader, val_dataloader, device=device)\n",
    "\n",
    "saved_state = torch.load(os.path.join(args.save_dir, args.save_as))\n",
    "model.load_state_dict(saved_state)\n",
    "print(\"Testing\")\n",
    "test(args, model, test_dataloader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='4.2'></a>\n",
    "4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ROI inputs\n",
      "/data/ornet/single_cells_cnns\n",
      "91\n",
      "91\n",
      "using weighted sampling\n",
      "Testing\n",
      "Accuracy: tensor(0.5000, device='cuda:0')\n",
      "['control', 'mdivi', 'llo']\n",
      "[[2 0 0]\n",
      " [1 1 0]\n",
      " [4 1 3]]\n"
     ]
    }
   ],
   "source": [
    "# 4.2\n",
    "args.save_as = \"roi_ResNet_weighted_05-18.pth\"\n",
    "saved_models.append(args.save_as)\n",
    "args.roi = True\n",
    "args.weighted_samples = True\n",
    "\n",
    "train_dataloader, test_dataloader, val_dataloader = get_dataloaders(\n",
    "    args, accept_list, resize=224)\n",
    "\n",
    "# model = BaseCNN()\n",
    "model = ResNet18(in_channels=2, resblock=ResBlock, outputs=3)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "if args.train:\n",
    "    print(\"Training\")\n",
    "    train(args, model, train_dataloader, val_dataloader, device=device)\n",
    "\n",
    "saved_state = torch.load(os.path.join(args.save_dir, args.save_as))\n",
    "model.load_state_dict(saved_state)\n",
    "print(\"Testing\")\n",
    "test(args, model, test_dataloader, device=device)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a690693c1fdd9d71c81918a527effb7319205501255b3eea75f291099e2d6564"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ornet': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
